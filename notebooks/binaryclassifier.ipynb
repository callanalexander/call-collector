{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b63464-367a-46b5-904c-c24d4c221ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE SPECTROGRAMS FOR TRAINING\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import io\n",
    "\n",
    "# Parameters\n",
    "n_mels = 256   # Number of Mel bands\n",
    "n_fft = 4096  # FFT size\n",
    "hop_length = 512\n",
    "fmax = 8000\n",
    "img_size = (224, 224)  # Size for EfficientNet/ResNet\n",
    "brightness_factor = 0.8  # Factor to adjust brightness\n",
    "contrast_factor = 2.0  # Factor to adjust contrast\n",
    "\n",
    "# Choose your colormap here\n",
    "colormap = 'viridis'  # Options: 'viridis', 'inferno', 'magma', 'cividis', 'plasma'\n",
    "\n",
    "def create_spectrogram(filename, save_path, cmap):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(filename, sr=None)\n",
    "    \n",
    "    # Generate mel-spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, n_mels=n_mels, fmax=fmax, hop_length=hop_length)\n",
    "    S_DB = librosa.power_to_db(S, ref=np.max, amin=1e-10, top_db=80)\n",
    "    \n",
    "    # Create figure for the spectrogram\n",
    "    fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "    librosa.display.specshow(S_DB, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel', fmax=fmax, cmap=cmap, ax=ax, vmin=S_DB.max() - 80, vmax=S_DB.max())\n",
    "    ax.axis('off')  # Remove axes\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Adjust margins to fill the figure\n",
    "\n",
    "    # Save the figure to a buffer\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Open the image and convert to RGB\n",
    "    img = Image.open(buf).convert('RGB')\n",
    "    img = img.resize(img_size)\n",
    "\n",
    "    # Adjust brightness and contrast\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(brightness_factor)\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(contrast_factor)\n",
    "\n",
    "    # Save the adjusted image\n",
    "    img.save(save_path)\n",
    "\n",
    "def process_directory(base_dir, sub_dirs, cmap):\n",
    "    for sub_dir in sub_dirs:\n",
    "        current_dir = os.path.join(base_dir, sub_dir)\n",
    "        save_dir = os.path.join(base_dir, 'spectrograms', sub_dir)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(current_dir):\n",
    "            if filename.endswith('.wav'):\n",
    "                file_path = os.path.join(current_dir, filename)\n",
    "                save_path = os.path.join(save_dir, os.path.splitext(filename)[0] + '.png')\n",
    "                create_spectrogram(file_path, save_path, cmap)\n",
    "                print(f\"Processed {filename}\")\n",
    "\n",
    "# Your directory setup\n",
    "base_dir = \"path_to_training_data\"\n",
    "sub_dirs = [\"positive\", \"negative\"]\n",
    "\n",
    "# Process directory with chosen colormap\n",
    "process_directory(base_dir, sub_dirs, colormap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d217be9-0828-43a5-8701-cf9620749a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hold out data for testing \n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def split_dataset(src_dir, test_size=0.05):\n",
    "    # Convert to Path object for easier handling\n",
    "    src_path = Path(src_dir)\n",
    "    \n",
    "    # Create test directory at same level as source directory\n",
    "    test_path = src_path.parent / 'test'\n",
    "    \n",
    "    # Create positive and negative directories in test folder\n",
    "    for class_name in ['positive', 'negative']:\n",
    "        test_class_path = test_path / class_name\n",
    "        test_class_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get list of all files in source class directory\n",
    "        src_class_path = src_path / class_name\n",
    "        all_files = list(src_class_path.glob('*'))\n",
    "        \n",
    "        # Calculate number of files to move to test\n",
    "        n_test = int(len(all_files) * test_size)\n",
    "        \n",
    "        # Randomly select files for test set\n",
    "        test_files = random.sample(all_files, n_test)\n",
    "        \n",
    "        # Move files to test directory\n",
    "        for file_path in test_files:\n",
    "            shutil.move(str(file_path), str(test_class_path / file_path.name))\n",
    "        \n",
    "        print(f\"Moved {n_test} files from {class_name} to test set\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "    \n",
    "    # Set source directory\n",
    "    src_dir = r\"C:\\Users\\calla\\Dropbox\\2024\\powerfulowl\\training_data_post_cluster\\spectrograms\"\n",
    "    \n",
    "    # Split the dataset\n",
    "    split_dataset(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ec4a5-93e1-497e-9546-3e42309c0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN MODEL\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def create_mobilenet():\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    # Freeze all layers except the last few for fine-tuning\n",
    "    for layer in base_model.layers[:-30]:  # Less layers to freeze since MobileNetV2 is smaller\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu')(x)  # Reduced the size of the dense layer\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)  # Reduced dropout rate\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Create and compile the model\n",
    "model = create_mobilenet()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Setup Data Generators with appropriate data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,  # Increased rotation\n",
    "    width_shift_range=0.1,  # Increased shift\n",
    "    height_shift_range=0.1,  # Increased shift\n",
    "    brightness_range=(0.8, 1.2),  # Same brightness adjustment\n",
    "    shear_range=0.05,  # Added shear transformation\n",
    "    zoom_range=0.1,  # Added zoom\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "base_dir = 'C:\\\\Users\\\\calla\\\\Dropbox\\\\2024\\\\powerfulowl\\\\training_data_post_cluster_v2\\\\spectrograms'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "]\n",
    "\n",
    "# Start training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fb108-a2c7-465c-88d9-a46d37a29eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('C:\\\\Users\\\\calla\\\\Dropbox\\\\2024\\\\powerfulowl\\\\training_data_v1\\\\models\\\\mobilenet_post_clusterv8.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd7cba-dc78-4cc9-8b14-441e39583a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model_path, test_data_path, save_path):\n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Setup test data generator\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(test_generator)\n",
    "    predicted_classes = (predictions > 0.5).astype(int)\n",
    "    true_classes = test_generator.classes\n",
    "    \n",
    "    # Calculate and print metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_classes, predicted_classes))\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate metrics from confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Calculate accuracy correctly\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    print(f\"\\nDetailed Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print(f\"True Negatives: {tn}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"True Positives: {tp}\")\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(true_classes, predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Save the plot instead of displaying it\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\nAUC-ROC Score: {roc_auc:.4f}\")\n",
    "    print(f\"ROC curve plot saved to: {save_path}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'auc_roc': roc_auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    }\n",
    "\n",
    "# Paths to your model and test data\n",
    "model_path = 'C:\\\\Users\\\\calla\\\\Dropbox\\\\2024\\\\powerfulowl\\\\training_data_v1\\\\models\\\\mobilenet_post_clusterv8.keras'\n",
    "test_data_path = 'C:\\\\Users\\\\calla\\\\Dropbox\\\\2024\\\\powerfulowl\\\\training_data_post_cluster\\\\test'\n",
    "save_path = 'C:\\\\Users\\\\calla\\\\Dropbox\\\\2024\\\\powerfulowl\\\\training_data_v1\\\\models\\\\roc_curve8.png'\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate_model(model_path, test_data_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa128f-2fdf-47f5-b27e-88ab074243ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infer on hour long audio files\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image, ImageEnhance\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import gc\n",
    "import logging\n",
    "import traceback\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Global variables\n",
    "model = None\n",
    "target_size = (224, 224)\n",
    "brightness_factor = 0.8\n",
    "contrast_factor = 2.0\n",
    "batch_size = 32\n",
    "duration = 5\n",
    "overlap = 2.5\n",
    "sample_rate = 48000\n",
    "\n",
    "# Thread-local storage for model\n",
    "thread_local = threading.local()\n",
    "\n",
    "def get_model():\n",
    "    if not hasattr(thread_local, 'model'):\n",
    "        thread_local.model = load_model('C:\\\\Users\\\\calla\\\\Dropbox\\\\2024\\\\powerfulowl\\\\training_data_v1\\\\models\\\\mobilenet_post_clusterv8.keras')\n",
    "    return thread_local.model\n",
    "\n",
    "def create_and_process_spectrogram(y, sr):\n",
    "    try:\n",
    "        if len(y) == 0:\n",
    "            logging.warning(\"Audio segment is empty\")\n",
    "            return None\n",
    "\n",
    "        S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, n_mels=256, fmax=24000, hop_length=512)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(3.5, 3.5))\n",
    "        img = ax.imshow(S_DB, aspect='auto', origin='lower', cmap='viridis')\n",
    "        ax.axis('off')\n",
    "        plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "        fig.canvas.draw()\n",
    "        img_array = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        img_array = img_array.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close(fig)\n",
    "\n",
    "        img = Image.fromarray(img_array).convert('RGB')\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        img = enhancer.enhance(brightness_factor)\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        img = enhancer.enhance(contrast_factor)\n",
    "        img = img.resize(target_size)\n",
    "\n",
    "        return img_to_array(img)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in create_and_process_spectrogram: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "def predict_chunk(chunk, sr, start_time):\n",
    "    try:\n",
    "        images = []\n",
    "        segment_times = []\n",
    "        segment_duration = 5\n",
    "        segment_samples = int(sr * segment_duration)\n",
    "        \n",
    "        for i in range(0, len(chunk), int(sr * (segment_duration - overlap))):\n",
    "            segment = chunk[i:i + segment_samples]\n",
    "            if len(segment) < segment_samples:\n",
    "                break\n",
    "            segment_time = start_time + i / sr\n",
    "            segment_times.append(segment_time)\n",
    "            img_array = create_and_process_spectrogram(segment, sr)\n",
    "            if img_array is not None:\n",
    "                images.append(img_array)\n",
    "\n",
    "        if not images:\n",
    "            return []\n",
    "\n",
    "        images = np.array(images)\n",
    "        images = (images / 255.0) * 2.0 - 1.0\n",
    "        model = get_model()\n",
    "        predictions = model.predict(images, batch_size=batch_size)\n",
    "        results = [(time, pred[0]) for time, pred in zip(segment_times, predictions)]\n",
    "        \n",
    "        del images\n",
    "        gc.collect()\n",
    "        \n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in predict_chunk at time {start_time}: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "        return []\n",
    "\n",
    "def process_file(filename, test_dir):\n",
    "    file_path = os.path.join(test_dir, filename)\n",
    "    try:\n",
    "        logging.info(f\"Started processing {filename}\")\n",
    "        chunk_duration = 300  # 5 minutes\n",
    "        \n",
    "        if not os.path.isfile(file_path) or not os.access(file_path, os.R_OK):\n",
    "            logging.error(f\"File does not exist or is not readable: {file_path}\")\n",
    "            return\n",
    "\n",
    "        all_results = []\n",
    "        start_time = 0\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                y, sr = librosa.load(file_path, sr=sample_rate, offset=start_time, duration=chunk_duration)\n",
    "                if len(y) == 0:\n",
    "                    break\n",
    "                chunk_results = predict_chunk(y, sr, start_time)\n",
    "                all_results.extend([(time, pred) for time, pred in chunk_results])\n",
    "                logging.info(f\"Processed chunk at {start_time} of {filename}, got {len(chunk_results)} results\")\n",
    "                start_time += chunk_duration\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing chunk at {start_time} of {filename}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "        if all_results:\n",
    "            positive_count = sum(1 for _, p in all_results if p > 0.01)\n",
    "            logging.info(f\"Detected {positive_count} potential owl calls out of {len(all_results)} segments in {filename}\")\n",
    "        else:\n",
    "            logging.warning(f\"No results produced for {filename}\")\n",
    "\n",
    "        # Write results to a CSV file for this audio file\n",
    "        csv_filename = f\"{os.path.splitext(filename)[0]}_predictions.csv\"\n",
    "        with open(csv_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Start Time (s)', 'Prediction'])\n",
    "            for time, prediction in all_results:\n",
    "                writer.writerow([time, prediction])\n",
    "        logging.info(f\"Wrote {len(all_results)} results to {csv_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {filename}: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "def main():\n",
    "    test_dir = 'J:\\\\harddrivepowls\\\\SM3\\\\sites\\\\chapelhill\\\\aprilmay'\n",
    "    logging.info(f\"Looking for WAV files in: {test_dir}\")\n",
    "\n",
    "    if not os.path.exists(test_dir):\n",
    "        logging.error(f\"Directory does not exist: {test_dir}\")\n",
    "        return\n",
    "\n",
    "    wav_files = [f for f in os.listdir(test_dir) if f.endswith('.wav')]\n",
    "    \n",
    "    if not wav_files:\n",
    "        logging.warning(f\"No WAV files found in {test_dir}\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Found {len(wav_files)} WAV files: {', '.join(wav_files)}\")\n",
    "\n",
    "    try:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "            futures = [executor.submit(process_file, filename, test_dir) for filename in wav_files]\n",
    "            concurrent.futures.wait(futures)\n",
    "        \n",
    "        logging.info(\"All files have been processed.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in main function: {str(e)}\")\n",
    "        logging.error(traceback.format_exc())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
